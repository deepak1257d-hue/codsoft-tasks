{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1AN57xabctg8ZV4DQAtOxsWBbEWdjCs2f","timestamp":1755546039119}],"authorship_tag":"ABX9TyPErxY6vSKRvu+kQc9lHg0V"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"hUDQqvZKobk1","executionInfo":{"status":"ok","timestamp":1755546200593,"user_tz":-330,"elapsed":4032,"user":{"displayName":"Deepak D","userId":"09664905006591151471"}}},"outputs":[],"source":["\n","\n","import os, re, io, joblib, numpy as np, pandas as pd, matplotlib.pyplot as plt\n","from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score, GridSearchCV\n","from sklearn.preprocessing import OneHotEncoder, StandardScaler, FunctionTransformer\n","from sklearn.compose import ColumnTransformer\n","from sklearn.pipeline import Pipeline\n","from sklearn.impute import SimpleImputer\n","from sklearn.metrics import classification_report, roc_auc_score, ConfusionMatrixDisplay, RocCurveDisplay\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.ensemble import RandomForestClassifier\n","\n","RANDOM_STATE = 42\n","np.random.seed(RANDOM_STATE)\n","pd.set_option(\"display.max_columns\", 200)\n"]},{"cell_type":"code","source":["\n","try:\n","    from google.colab import files\n","    print(\"If you want, upload a file now (e.g., Titanic-Dataset (2).csv).\")\n","except:\n","    pass\n","\n","df = None\n","\n","\n","local_paths = [\n","    \"/content/Titanic-Dataset (2).csv\",\n","    \"/content/titanic.csv\",\n","]\n","\n","for p in local_paths:\n","    if os.path.exists(p):\n","        df = pd.read_csv(p)\n","        print(f\"Loaded from {p}\")\n","        break\n","if df is None:\n","    try:\n","        uploaded = files.upload()\n","        fname = list(uploaded.keys())[0]\n","        df = pd.read_csv(io.BytesIO(uploaded[fname]))\n","        print(f\"Loaded from uploaded file: {fname}\")\n","    except Exception as e:\n","        raise SystemExit(\"No file provided. Please upload your Titanic CSV.\")\n","\n","print(df.head(3))\n","print(df.shape, \"rows x columns\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":382},"id":"xQvJkefhopZz","executionInfo":{"status":"ok","timestamp":1755546221134,"user_tz":-330,"elapsed":14943,"user":{"displayName":"Deepak D","userId":"09664905006591151471"}},"outputId":"a6b0a02d-9f9b-4df1-e826-453e6aeed280","collapsed":true},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["If you want, upload a file now (e.g., Titanic-Dataset (2).csv).\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-cd29a8ee-d6e9-412c-8175-988e6f2b69ba\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-cd29a8ee-d6e9-412c-8175-988e6f2b69ba\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving Titanic-Dataset (2).csv to Titanic-Dataset (2).csv\n","Loaded from uploaded file: Titanic-Dataset (2).csv\n","   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","(891, 12) rows x columns\n"]}]},{"cell_type":"code","source":["\n","print(\"\\nColumns:\", df.columns.tolist())\n","print(\"\\nInfo:\")\n","print(df.info())\n","COLUMN_MAP = {\n","    'survived': 'Survived',\n","    'pclass': 'Pclass',\n","    'sex': 'Sex',\n","    'age': 'Age',\n","    'sibsp': 'SibSp',\n","    'parch': 'Parch',\n","    'fare': 'Fare',\n","    'embarked': 'Embarked',\n","    'cabin': 'Cabin',\n","    'ticket': 'Ticket',\n","    'name': 'Name',\n","}\n","\n","df = df.rename(columns={c: COLUMN_MAP.get(c, c) for c in df.columns.str.lower()})\n","\n","\n","assert 'Survived' in df.columns, \"Couldn't find a 'Survived' column. Please rename your target to 'Survived'.\"\n","\n","\n","if df['Survived'].dtype != 'int64' and df['Survived'].dtype != 'int32':\n","    df['Survived'] = df['Survived'].astype(int)\n","\n","print(\"\\nTarget distribution:\")\n","print(df['Survived'].value_counts(dropna=False))\n","\n","\n","missing = df.isna().mean().sort_values(ascending=False)\n","print(\"\\nMissingness (top 15):\")\n","print((missing * 100).round(1).head(15).astype(str) + \"%\")\n"],"metadata":{"id":"zAcuFqfto2YN"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# ==== Feature Engineering ====\n","def engineer_features(X: pd.DataFrame) -> pd.DataFrame:\n","    X = X.copy()\n","    # Ensure needed columns exist, create empties if missing (robustness)\n","    for col in ['Name','Cabin','Ticket','Embarked','Sex','Age','Fare','SibSp','Parch','Pclass']:\n","        if col not in X.columns:\n","            X[col] = np.nan\n","\n","    # Title from Name\n","    title = (\n","        X['Name']\n","        .fillna('')\n","        .str.extract(r',\\s*([^\\.]+)\\.', expand=False)\n","        .str.strip()\n","    )\n","    # Group rare titles\n","    title_map = {\n","        'Mlle':'Miss','Ms':'Miss','Mme':'Mrs','Lady':'Royalty','Countess':'Royalty','Dona':'Royalty',\n","        'Sir':'Royalty','Don':'Royalty','Jonkheer':'Royalty','Capt':'Officer','Col':'Officer',\n","        'Major':'Officer','Dr':'Officer','Rev':'Officer'\n","    }\n","    title = title.replace(title_map)\n","    title = title.fillna('Unknown')\n","\n","    # Deck from Cabin\n","    deck = X['Cabin'].astype(str).str[0]\n","    deck = deck.where(deck.str.match(r'[A-Za-z]'), 'U').fillna('U')\n","\n","    # Family features\n","    family_size = X['SibSp'].fillna(0).astype(float) + X['Parch'].fillna(0).astype(float) + 1\n","    is_alone = (family_size == 1).astype(int)\n","\n","    # Ticket prefix\n","    ticket_prefix = (\n","        X['Ticket']\n","        .astype(str)\n","        .str.replace(r'\\d', '', regex=True)\n","        .str.replace(r'[\\./\\s]+', '', regex=True)\n","        .str.upper()\n","    )\n","    ticket_prefix = ticket_prefix.replace('', 'NONE').fillna('NONE')\n","\n","    # Clean Embarked\n","    embarked = X['Embarked'].astype(str).replace({'nan': np.nan})\n","\n","    # Build final modeling frame\n","    out = pd.DataFrame({\n","        'Pclass': X['Pclass'],\n","        'Sex': X['Sex'],\n","        'Age': X['Age'],\n","        'SibSp': X['SibSp'],\n","        'Parch': X['Parch'],\n","        'Fare': X['Fare'],\n","        'Embarked': embarked,\n","        'Title': title,\n","        'Deck': deck,\n","        'FamilySize': family_size,\n","        'IsAlone': is_alone,\n","        'TicketPrefix': ticket_prefix\n","    })\n","\n","    return out\n","\n","engineered_preview = engineer_features(df.head(10))\n","engineered_preview.head()\n"],"metadata":{"id":"yj1f4nELo598"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","X_full = df.drop(columns=['Survived'])\n","y = df['Survived'].astype(int)\n","\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X_full, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",")\n","\n","X_train.shape, X_test.shape\n"],"metadata":{"id":"FKfx-CTMpAPp"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","numeric_features = ['Age','SibSp','Parch','Fare','FamilySize','IsAlone','Pclass']\n","categorical_features = ['Sex','Embarked','Title','Deck','TicketPrefix']\n","\n","numeric_pipe = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='median')),\n","    ('scaler', StandardScaler())\n","])\n","\n","categorical_pipe = Pipeline(steps=[\n","    ('imputer', SimpleImputer(strategy='most_frequent')),\n","    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))\n","])\n","\n","preprocess = ColumnTransformer(transformers=[\n","    ('num', numeric_pipe, numeric_features),\n","    ('cat', categorical_pipe, categorical_features)\n","])\n","\n","logreg_clf = LogisticRegression(max_iter=1000)\n","logreg_pipeline = Pipeline(steps=[\n","    ('feat', FunctionTransformer(engineer_features, validate=False).set_output(transform=\"pandas\")),\n","    ('preprocess', preprocess),\n","    ('model', logreg_clf)\n","])\n","\n","\n","cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n","cv_auc = cross_val_score(logreg_pipeline, X_train, y_train, scoring='roc_auc', cv=cv, n_jobs=-1)\n","\n","print(\"LogReg CV AUC:\", cv_auc.round(3), \"mean:\", cv_auc.mean().round(3))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rDQ483edpHbd","executionInfo":{"status":"ok","timestamp":1755545679318,"user_tz":-330,"elapsed":2256,"user":{"displayName":"Deepak D","userId":"09664905006591151471"}},"outputId":"bd693b54-d231-4801-9a78-2cea33abaa08"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["LogReg CV AUC: [0.864 0.857 0.911 0.855 0.877] mean: 0.873\n"]}]},{"cell_type":"code","source":["\n","logreg_pipeline.fit(X_train, y_train)\n","\n","pred = logreg_pipeline.predict(X_test)\n","proba = logreg_pipeline.predict_proba(X_test)[:, 1]\n","\n","print(\"\\nClassification report (LogReg):\\n\")\n","print(classification_report(y_test, pred, digits=3))\n","print(\"ROC AUC (test):\", roc_auc_score(y_test, proba).round(3))\n","\n","ConfusionMatrixDisplay.from_estimator(logreg_pipeline, X_test, y_test)\n","plt.title(\"Confusion Matrix – Logistic Regression\")\n","plt.show()\n","\n","RocCurveDisplay.from_predictions(y_test, proba)\n","plt.title(\"ROC – Logistic Regression\")\n","plt.show()\n"],"metadata":{"id":"SSZAyTo_pbas"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","\n","rf = RandomForestClassifier(\n","    n_estimators=500,\n","    random_state=RANDOM_STATE,\n","    n_jobs=-1\n",")\n","\n","rf_pipeline = Pipeline(steps=[\n","    ('feat', FunctionTransformer(engineer_features, validate=False).set_output(transform=\"pandas\")),\n","    ('preprocess', preprocess),\n","    ('rf', rf)\n","])\n","\n","param_grid = {\n","    'rf__max_depth': [None, 6, 10],\n","    'rf__min_samples_split': [2, 5],\n","    'rf__min_samples_leaf': [1, 2],\n","    'rf__max_features': ['sqrt', 'log2']\n","}\n","\n","grid = GridSearchCV(\n","    rf_pipeline,\n","    param_grid=param_grid,\n","    scoring='roc_auc',\n","    cv=cv,\n","    n_jobs=-1,\n","    verbose=0\n",")\n","\n","grid.fit(X_train, y_train)\n","\n","print(\"Best AUC (CV):\", grid.best_score_.round(3))\n","print(\"Best params:\", grid.best_params_)\n","\n","best_rf = grid.best_estimator_\n","pred_rf = best_rf.predict(X_test)\n","proba_rf = best_rf.predict_proba(X_test)[:, 1]\n","\n","print(\"\\nClassification report (RandomForest):\\n\")\n","print(classification_report(y_test, pred_rf, digits=3))\n","print(\"ROC AUC (test):\", roc_auc_score(y_test, proba_rf).round(3))\n","\n","ConfusionMatrixDisplay.from_estimator(best_rf, X_test, y_test)\n","plt.title(\"Confusion Matrix – Random Forest\")\n","plt.show()\n","\n","RocCurveDisplay.from_predictions(y_test, proba_rf)\n","plt.title(\"ROC – Random Forest\")\n","plt.show()\n"],"metadata":{"id":"hHGuylR7pjXU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","prep = best_rf.named_steps['preprocess']\n","ohe = prep.named_transformers_['cat'].named_steps['onehot']\n","\n","cat_ohe_names = ohe.get_feature_names_out(categorical_features).tolist()\n","feature_names = numeric_features + cat_ohe_names\n","\n","importances = best_rf.named_steps['rf'].feature_importances_\n","fi = pd.DataFrame({'feature': feature_names, 'importance': importances}).sort_values('importance', ascending=False)\n","\n","fi.head(20)\n"],"metadata":{"id":"Fh9TiG5hqOtL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","joblib.dump(best_rf, \"titanic_survival_pipeline.pkl\")\n","print(\"Saved to titanic_survival_pipeline.pkl\")\n","loaded = joblib.load(\"titanic_survival_pipeline.pkl\")\n","one_passenger = pd.DataFrame([{\n","    \"Pclass\": 3,\n","    \"Sex\": \"male\",\n","    \"Age\": 22,\n","    \"SibSp\": 1,\n","    \"Parch\": 0,\n","    \"Fare\": 7.25,\n","    \"Embarked\": \"S\",\n","    \"Cabin\": None,\n","    \"Ticket\": \"A/5 21171\",\n","    \"Name\": \"Mr. Owen Harris Braund\"\n","}])\n","\n","pred_class = loaded.predict(one_passenger)[0]\n","pred_prob = loaded.predict_proba(one_passenger)[0,1]\n","print(f\"Predicted Survived: {pred_class}  |  Probability: {pred_prob:.3f}\")\n"],"metadata":{"id":"yKe296IDqTE-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def eval_model(name, pipe, X_tr, y_tr, X_te, y_te):\n","    y_prob = pipe.predict_proba(X_te)[:,1]\n","    y_hat  = (y_prob >= 0.5).astype(int)\n","    report = classification_report(y_te, y_hat, digits=3, output_dict=True)\n","    return {\n","        'model': name,\n","        'auc': roc_auc_score(y_te, y_prob),\n","        'precision': report['1']['precision'],\n","        'recall': report['1']['recall'],\n","        'f1': report['1']['f1-score'],\n","        'accuracy': report['accuracy']\n","    }\n","\n","logreg_metrics = eval_model(\"LogReg\", logreg_pipeline, X_train, y_train, X_test, y_test)\n","rf_metrics = eval_model(\"RandomForest\", best_rf, X_train, y_train, X_test, y_test)\n","pd.DataFrame([logreg_metrics, rf_metrics]).round(3)\n"],"metadata":{"id":"mo-b9sQAqYaU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn.metrics import classification_report, roc_auc_score\n","y_pred = logreg_pipeline.predict(X_test)\n","y_proba = logreg_pipeline.predict_proba(X_test)[:, 1]\n","print(classification_report(y_test, y_pred))\n","print(\"AUC:\", roc_auc_score(y_test, y_proba))\n","y_pred_rf = best_rf.predict(X_test)\n","y_proba_rf = best_rf.predict_proba(X_test)[:, 1]\n","print(classification_report(y_test, y_pred_rf))\n","print(\"AUC:\", roc_auc_score(y_test, y_proba_rf))\n"],"metadata":{"id":"wjIdSSYwqx7N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","\n","new_passenger = pd.DataFrame([{\n","    \"Pclass\": 3,\n","    \"Sex\": \"male\",\n","    \"Age\": 22,\n","    \"SibSp\": 1,\n","    \"Parch\": 0,\n","    \"Fare\": 7.25,\n","    \"Embarked\": \"S\",\n","    \"Cabin\": None,\n","    \"Ticket\": \"A/5 21171\",\n","    \"Name\": \"Mr. Owen Harris Braund\"\n","}])\n","\n","print(\"LogReg prediction:\", logreg_pipeline.predict(new_passenger)[0])\n","print(\"LogReg survival probability:\", logreg_pipeline.predict_proba(new_passenger)[0,1])\n","\n","print(\"RandomForest prediction:\", best_rf.predict(new_passenger)[0])\n","print(\"RandomForest survival probability:\", best_rf.predict_proba(new_passenger)[0,1])\n"],"metadata":{"id":"9Rm0uOcHq2C6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["child_passenger = pd.DataFrame([{\n","    \"Pclass\": 3,\n","    \"Sex\": \"female\",\n","    \"Age\": 8,\n","    \"SibSp\": 1,\n","    \"Parch\": 2,\n","    \"Fare\": 21.0,\n","    \"Embarked\": \"S\",\n","    \"Cabin\": None,\n","    \"Ticket\": \"347742\",\n","    \"Name\": \"Miss. Little Girl\"\n","}])\n","\n","print(\"LogReg:\", logreg_pipeline.predict(child_passenger)[0],\n","      \"Prob:\", logreg_pipeline.predict_proba(child_passenger)[0,1])\n","\n","print(\"RandomForest:\", best_rf.predict(child_passenger)[0],\n","      \"Prob:\", best_rf.predict_proba(child_passenger)[0,1])\n"],"metadata":{"id":"LCQjOdOZrM5u"},"execution_count":null,"outputs":[]}]}